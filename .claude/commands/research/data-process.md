---
description: 'ä¼ æ„Ÿå™¨æ•°æ®å¤„ç† - å¯¼å…¥ã€æ¸…æ´—ã€é¢„å¤„ç†æ—¶åºæ•°æ®'
---

# /data:process - æ•°æ®å¤„ç†

$ARGUMENTS

---

## ä¾èµ–èƒ½åŠ›

- `data.load` - æ•°æ®åŠ è½½ (ç”¨æˆ·é…ç½®)
- `data.plot` - æ•°æ®å¯è§†åŒ– (ç”¨æˆ·é…ç½®)
- `docs.query` - Pandas/NumPy æ–‡æ¡£ (context7)

## æ‰§è¡Œæµç¨‹

### 1. ä¸Šä¸‹æ–‡æ£€ç´¢
- è°ƒç”¨ `mcp__ace-tool__search_context` æ£€æŸ¥é¡¹ç›®ä¸­çš„æ•°æ®æ–‡ä»¶

### 2. å‚æ•°æ ¡éªŒ
æ£€æŸ¥è¾“å…¥æ˜¯å¦åŒ…å«:
- **æ•°æ®æ–‡ä»¶è·¯å¾„**: CSV, Excel, HDF5, MAT ç­‰
- **å¤„ç†æ“ä½œ**: æ¸…æ´—ã€æ»¤æ³¢ã€é‡é‡‡æ ·ã€ç‰¹å¾æå–
- **è¾“å‡ºæ ¼å¼**: CSV, NPY, HDF5

### 3. è®¡åˆ’é¢„è§ˆ

```markdown
## ğŸ“‹ æ‰§è¡Œè®¡åˆ’

| æ­¥éª¤ | æ“ä½œ | é£é™©ç­‰çº§ |
|------|------|----------|
| 1 | åŠ è½½æ•°æ® + è·å– Pandas/NumPy æ–‡æ¡£ | low |
| 2 | Codex ç”Ÿæˆå¤„ç†è„šæœ¬ | low |
| 3 | æ‰§è¡Œæ•°æ®å¤„ç† | low |
| 4 | ç”Ÿæˆå¤„ç†æŠ¥å‘Š + å¯è§†åŒ– | low |

**é¢„è®¡å½±å“**:
- ç”Ÿæˆå¤„ç†åæ•°æ®: `artifacts/processed-data/[filename]-processed.csv`
- ç”Ÿæˆå¤„ç†æŠ¥å‘Š: `artifacts/reports/data-process-report.md`
```

### 4. ç¡®è®¤é—¨æ§
- **é£é™©ç­‰çº§**: low
- **è¡Œä¸º**: auto - è‡ªåŠ¨æ‰§è¡Œ

### 5. æ‰§è¡Œ

#### Step 1: é¢„æ£€ç´¢ Pandas/NumPy æ–‡æ¡£
ä½¿ç”¨ context7 è·å–æ•°æ®å¤„ç†æœ€ä½³å®è·µ:
```javascript
mcp__context7__resolve-library-id({
  libraryName: "pandas",
  query: "pandas time series processing, filtering, resampling"
})

mcp__context7__query-docs({
  libraryId: "/pandas/pandas",
  query: "æ—¶åºæ•°æ®å¤„ç†ã€ç¼ºå¤±å€¼å¤„ç†ã€æ»¤æ³¢ã€é‡é‡‡æ ·ç¤ºä¾‹"
})
```

#### Step 2: Codex ç”Ÿæˆå¤„ç†è„šæœ¬

```bash
C:/Users/ljh/.claude/bin/codeagent-wrapper.exe --backend codex - "$PWD" <<'EOF'
ROLE_FILE: C:/Users/ljh/.claude/.ccg/prompts/codex/architect.md
<TASK>
ä»»åŠ¡ç±»å‹: ä¼ æ„Ÿå™¨æ•°æ®å¤„ç†è„šæœ¬
éœ€æ±‚: [ç”¨æˆ·æ•°æ®å¤„ç†éœ€æ±‚]
ä¸Šä¸‹æ–‡:
- æ•°æ®æ–‡ä»¶: [data-file-path]
- æ•°æ®æ ¼å¼: [CSV, Excel, HDF5]
- å¤„ç†æ“ä½œ: [å»å™ªã€é‡é‡‡æ ·ã€ç‰¹å¾æå–]
- Pandas/NumPy æ–‡æ¡£ (from context7):
  [æ•°æ®å¤„ç†æœ€ä½³å®è·µ]
ç”Ÿæˆå†…å®¹:
1. æ•°æ®åŠ è½½ä¸æ¢ç´¢
2. æ•°æ®æ¸…æ´— (ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼)
3. æ•°æ®å¤„ç† (æ»¤æ³¢ã€é‡é‡‡æ ·)
4. ç‰¹å¾æå– (å¯é€‰)
5. æ•°æ®å¯¼å‡º
</TASK>
OUTPUT: å®Œæ•´ Python è„šæœ¬
æ³¨æ„äº‹é¡¹:
1. æ·»åŠ æ•°æ®è´¨é‡æ£€æŸ¥
2. å¯è§†åŒ–å¤„ç†å‰åå¯¹æ¯”
3. è®°å½•å¤„ç†å‚æ•°
EOF
```

Codex è¿”å›ç¤ºä¾‹è„šæœ¬:
```python
#!/usr/bin/env python
# process_sensor_data.py
# Generated by /data:process

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal

# é…ç½®
INPUT_FILE = 'sensor_data.csv'
OUTPUT_FILE = 'artifacts/processed-data/sensor_data-processed.csv'
SAMPLING_RATE = 1000  # Hz
FILTER_CUTOFF = 50    # Hz

# åŠ è½½æ•°æ®
print("Loading data...")
df = pd.read_csv(INPUT_FILE, parse_dates=['timestamp'])
print(f"Loaded {len(df)} data points")

# æ•°æ®è´¨é‡æ£€æŸ¥
print("\n=== Data Quality Check ===")
print(f"Missing values: {df.isnull().sum().sum()}")
print(f"Duplicate rows: {df.duplicated().sum()}")
print(f"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}")

# å¤„ç†ç¼ºå¤±å€¼
df = df.dropna()  # æˆ–ä½¿ç”¨æ’å€¼: df.interpolate(method='linear')

# å»é™¤å¼‚å¸¸å€¼ (3-sigma)
for col in df.select_dtypes(include=[np.number]).columns:
    mean = df[col].mean()
    std = df[col].std()
    df = df[(df[col] >= mean - 3*std) & (df[col] <= mean + 3*std)]

# ä½é€šæ»¤æ³¢
print("\n=== Filtering ===")
nyquist = SAMPLING_RATE / 2
b, a = signal.butter(4, FILTER_CUTOFF / nyquist, btype='low')

for col in ['sensor1', 'sensor2', 'sensor3']:
    df[f'{col}_filtered'] = signal.filtfilt(b, a, df[col])

# é‡é‡‡æ · (å¯é€‰)
# df = df.set_index('timestamp').resample('1S').mean()

# å¯¼å‡º
df.to_csv(OUTPUT_FILE, index=False)
print(f"\nProcessed data saved to {OUTPUT_FILE}")

# å¯è§†åŒ–å¯¹æ¯”
fig, axes = plt.subplots(3, 1, figsize=(12, 8))
for i, col in enumerate(['sensor1', 'sensor2', 'sensor3']):
    axes[i].plot(df['timestamp'], df[col], alpha=0.5, label='Original')
    axes[i].plot(df['timestamp'], df[f'{col}_filtered'], label='Filtered')
    axes[i].set_ylabel(col)
    axes[i].legend()
    axes[i].grid(True, alpha=0.3)
axes[-1].set_xlabel('Timestamp')
plt.tight_layout()
plt.savefig('artifacts/figures/data-processing-comparison.png', dpi=300)
print("Comparison plot saved to artifacts/figures/data-processing-comparison.png")
```

#### Step 3: æ‰§è¡Œå¤„ç†è„šæœ¬
```bash
python scripts/process_sensor_data.py
```

#### Step 4: ç”Ÿæˆå¤„ç†æŠ¥å‘Š

```markdown
# æ•°æ®å¤„ç†æŠ¥å‘Š
**æ•°æ®æ–‡ä»¶**: sensor_data.csv
**å¤„ç†æ—¶é—´**: 2026-01-17 10:30:45

---

## æ•°æ®æ¦‚è§ˆ
- åŸå§‹æ•°æ®ç‚¹: 100,000
- å¤„ç†åæ•°æ®ç‚¹: 98,765 (-1.2%)
- æ—¶é—´èŒƒå›´: 2025-01-01 00:00:00 to 2025-01-31 23:59:59
- é‡‡æ ·ç‡: 1000 Hz

## æ•°æ®è´¨é‡
- ç¼ºå¤±å€¼: 100 (0.1%)
- å¼‚å¸¸å€¼: 1,135 (1.1%, 3-sigma å‰”é™¤)
- é‡å¤è¡Œ: 0

## å¤„ç†æ“ä½œ
1. **ç¼ºå¤±å€¼å¤„ç†**: åˆ é™¤ (æˆ–çº¿æ€§æ’å€¼)
2. **å¼‚å¸¸å€¼å‰”é™¤**: 3-sigma å‡†åˆ™
3. **ä½é€šæ»¤æ³¢**: Butterworth 4é˜¶, æˆªæ­¢é¢‘ç‡ 50 Hz
4. **é‡é‡‡æ ·**: (æœªæ‰§è¡Œ)

## å¤„ç†å‰åå¯¹æ¯”
![](artifacts/figures/data-processing-comparison.png)

## ç»Ÿè®¡ä¿¡æ¯
| ä¼ æ„Ÿå™¨ | å‡å€¼ (åŸå§‹) | å‡å€¼ (å¤„ç†å) | æ ‡å‡†å·® (åŸå§‹) | æ ‡å‡†å·® (å¤„ç†å) |
|--------|-------------|---------------|---------------|-----------------|
| sensor1 | 1.234 | 1.230 | 0.567 | 0.123 |
| sensor2 | 2.345 | 2.340 | 0.678 | 0.234 |
| sensor3 | 3.456 | 3.450 | 0.789 | 0.345 |

## ç”Ÿæˆæ–‡ä»¶
- å¤„ç†åæ•°æ®: `artifacts/processed-data/sensor_data-processed.csv`
- å¤„ç†è„šæœ¬: `scripts/process_sensor_data.py`
- å¯¹æ¯”å›¾è¡¨: `artifacts/figures/data-processing-comparison.png`
```

### 6. ç»“æœå‘ˆç°

```markdown
## âœ… æ•°æ®å¤„ç†å®Œæˆ

### å¤„ç†æ‘˜è¦
- åŸå§‹æ•°æ®: 100,000 ç‚¹
- å¤„ç†åæ•°æ®: 98,765 ç‚¹
- æ•°æ®è´¨é‡æå‡: å™ªå£°é™ä½ 78%

### ç”Ÿæˆæ–‡ä»¶
- å¤„ç†åæ•°æ®: `artifacts/processed-data/sensor_data-processed.csv`
- å¤„ç†æŠ¥å‘Š: `artifacts/reports/data-process-report.md`
- å¯¹æ¯”å›¾è¡¨: `artifacts/figures/data-processing-comparison.png`

### åç»­æ“ä½œ
- ä»¿çœŸ-å®æµ‹å¯¹æ¯”: `/data:compare --sim sim-results.csv --exp sensor_data-processed.csv`
- ML è®­ç»ƒ: `/data:train --data sensor_data-processed.csv`
- æ—¶åºåˆ†æ: `/data:process --timeseries sensor_data-processed.csv`
```

---

## å¤„ç†æ“ä½œ

### æ•°æ®æ¸…æ´—
```bash
# ç¼ºå¤±å€¼å¤„ç†
/data:process data.csv --missing drop  # åˆ é™¤
/data:process data.csv --missing interpolate  # æ’å€¼

# å¼‚å¸¸å€¼æ£€æµ‹
/data:process data.csv --outlier 3-sigma
/data:process data.csv --outlier iqr  # å››åˆ†ä½è·
```

### æ»¤æ³¢
```bash
# ä½é€šæ»¤æ³¢
/data:process data.csv --filter lowpass --cutoff 50

# é«˜é€šæ»¤æ³¢
/data:process data.csv --filter highpass --cutoff 0.1

# å¸¦é€šæ»¤æ³¢
/data:process data.csv --filter bandpass --cutoff 1,100
```

### é‡é‡‡æ ·
```bash
# é™é‡‡æ ·
/data:process data.csv --resample 100Hz

# å‡é‡‡æ ·
/data:process data.csv --resample 10kHz --method cubic
```

### ç‰¹å¾æå–
```bash
# ç»Ÿè®¡ç‰¹å¾
/data:process data.csv --features mean,std,max,min

# é¢‘åŸŸç‰¹å¾
/data:process data.csv --features fft,psd

# æ—¶é¢‘ç‰¹å¾
/data:process data.csv --features wavelet
```

---

## å¤šæ¨¡å‹åä½œ

**åä½œæ¨¡å¼**: Codex ä¸»å¯¼

| æ¨¡å‹ | èŒè´£ | è¾“å‡º |
|------|------|------|
| **Context7** | æä¾› Pandas/NumPy/SciPy æ–‡æ¡£ | æ•°æ®å¤„ç†æœ€ä½³å®è·µ |
| **Codex** | ç”Ÿæˆæ•°æ®å¤„ç†è„šæœ¬ | Python è„šæœ¬ |
| **Claude** | é¢„æ£€ç´¢æ–‡æ¡£ã€æ‰§è¡Œè„šæœ¬ã€ç”ŸæˆæŠ¥å‘Š | å¤„ç†åæ•°æ® + æŠ¥å‘Š |

---

## å‚è€ƒ

- å…±äº«åè®®: `.claude/commands/research/_protocol.md`
- èƒ½åŠ›é…ç½®: `.claude/.research/capabilities.yaml`
- ä»¿çœŸ-å®æµ‹å¯¹æ¯”: `/data:compare`
- ML è®­ç»ƒ: `/data:train`
